{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 4., 5., 1.],\n",
       "        [1., 4., 3., 4., 3.],\n",
       "        [4., 5., 1., 0., 5.],\n",
       "        [5., 0., 2., 3., 3.],\n",
       "        [0., 2., 1., 1., 1.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(0,6,(5,5))\n",
    "X = torch.FloatTensor(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_dims):\n",
    "        super().__init__()\n",
    "        self.users = nn.Embedding(n_users, n_dims)\n",
    "        self.items = nn.Embedding(n_items, n_dims)\n",
    "        self.users.weight.data.uniform_(0, 0.1)\n",
    "        self.items.weight.data.uniform_(0, 0.1)\n",
    "    \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embed = self.users(user_ids)\n",
    "        item_embed = self.items(item_ids)\n",
    "        \n",
    "        predicted_ratings = (user_embed * item_embed).sum(dim=1)\n",
    "        return predicted_ratings\n",
    "\n",
    "n_users = 5\n",
    "n_items = 5\n",
    "n_dims = 3\n",
    "\n",
    "model = MFModel(n_users, n_items, n_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 10.0326\n",
      "Epoch: 10, Loss: 9.6667\n",
      "Epoch: 20, Loss: 8.9205\n",
      "Epoch: 30, Loss: 7.7697\n",
      "Epoch: 40, Loss: 6.2913\n",
      "Epoch: 50, Loss: 4.6959\n",
      "Epoch: 60, Loss: 3.2732\n",
      "Epoch: 70, Loss: 2.2444\n",
      "Epoch: 80, Loss: 1.6679\n",
      "Epoch: 90, Loss: 1.4258\n",
      "Epoch: 100, Loss: 1.3220\n",
      "Epoch: 110, Loss: 1.2553\n",
      "Epoch: 120, Loss: 1.2153\n",
      "Epoch: 130, Loss: 1.1966\n",
      "Epoch: 140, Loss: 1.1881\n",
      "Epoch: 150, Loss: 1.1837\n",
      "Epoch: 160, Loss: 1.1810\n",
      "Epoch: 170, Loss: 1.1789\n",
      "Epoch: 180, Loss: 1.1767\n",
      "Epoch: 190, Loss: 1.1743\n",
      "Epoch: 200, Loss: 1.1711\n",
      "Epoch: 210, Loss: 1.1667\n",
      "Epoch: 220, Loss: 1.1608\n",
      "Epoch: 230, Loss: 1.1523\n",
      "Epoch: 240, Loss: 1.1404\n",
      "Epoch: 250, Loss: 1.1235\n",
      "Epoch: 260, Loss: 1.0997\n",
      "Epoch: 270, Loss: 1.0664\n",
      "Epoch: 280, Loss: 1.0208\n",
      "Epoch: 290, Loss: 0.9603\n",
      "Epoch: 300, Loss: 0.8831\n",
      "Epoch: 310, Loss: 0.7907\n",
      "Epoch: 320, Loss: 0.6891\n",
      "Epoch: 330, Loss: 0.5887\n",
      "Epoch: 340, Loss: 0.5019\n",
      "Epoch: 350, Loss: 0.4375\n",
      "Epoch: 360, Loss: 0.3957\n",
      "Epoch: 370, Loss: 0.3702\n",
      "Epoch: 380, Loss: 0.3534\n",
      "Epoch: 390, Loss: 0.3403\n",
      "Epoch: 400, Loss: 0.3292\n",
      "Epoch: 410, Loss: 0.3198\n",
      "Epoch: 420, Loss: 0.3118\n",
      "Epoch: 430, Loss: 0.3050\n",
      "Epoch: 440, Loss: 0.2992\n",
      "Epoch: 450, Loss: 0.2940\n",
      "Epoch: 460, Loss: 0.2893\n",
      "Epoch: 470, Loss: 0.2848\n",
      "Epoch: 480, Loss: 0.2803\n",
      "Epoch: 490, Loss: 0.2754\n",
      "Epoch: 500, Loss: 0.2699\n",
      "Epoch: 510, Loss: 0.2634\n",
      "Epoch: 520, Loss: 0.2554\n",
      "Epoch: 530, Loss: 0.2455\n",
      "Epoch: 540, Loss: 0.2331\n",
      "Epoch: 550, Loss: 0.2178\n",
      "Epoch: 560, Loss: 0.1991\n",
      "Epoch: 570, Loss: 0.1770\n",
      "Epoch: 580, Loss: 0.1520\n",
      "Epoch: 590, Loss: 0.1252\n",
      "Epoch: 600, Loss: 0.0987\n",
      "Epoch: 610, Loss: 0.0747\n",
      "Epoch: 620, Loss: 0.0552\n",
      "Epoch: 630, Loss: 0.0411\n",
      "Epoch: 640, Loss: 0.0320\n",
      "Epoch: 650, Loss: 0.0268\n",
      "Epoch: 660, Loss: 0.0240\n",
      "Epoch: 670, Loss: 0.0223\n",
      "Epoch: 680, Loss: 0.0212\n",
      "Epoch: 690, Loss: 0.0204\n",
      "Epoch: 700, Loss: 0.0198\n",
      "Epoch: 710, Loss: 0.0193\n",
      "Epoch: 720, Loss: 0.0189\n",
      "Epoch: 730, Loss: 0.0185\n",
      "Epoch: 740, Loss: 0.0183\n",
      "Epoch: 750, Loss: 0.0180\n",
      "Epoch: 760, Loss: 0.0178\n",
      "Epoch: 770, Loss: 0.0176\n",
      "Epoch: 780, Loss: 0.0174\n",
      "Epoch: 790, Loss: 0.0172\n",
      "Epoch: 800, Loss: 0.0170\n",
      "Epoch: 810, Loss: 0.0168\n",
      "Epoch: 820, Loss: 0.0166\n",
      "Epoch: 830, Loss: 0.0165\n",
      "Epoch: 840, Loss: 0.0163\n",
      "Epoch: 850, Loss: 0.0161\n",
      "Epoch: 860, Loss: 0.0159\n",
      "Epoch: 870, Loss: 0.0157\n",
      "Epoch: 880, Loss: 0.0155\n",
      "Epoch: 890, Loss: 0.0153\n",
      "Epoch: 900, Loss: 0.0151\n",
      "Epoch: 910, Loss: 0.0150\n",
      "Epoch: 920, Loss: 0.0148\n",
      "Epoch: 930, Loss: 0.0146\n",
      "Epoch: 940, Loss: 0.0144\n",
      "Epoch: 950, Loss: 0.0142\n",
      "Epoch: 960, Loss: 0.0140\n",
      "Epoch: 970, Loss: 0.0138\n",
      "Epoch: 980, Loss: 0.0137\n",
      "Epoch: 990, Loss: 0.0135\n"
     ]
    }
   ],
   "source": [
    "user_ids, item_ids = X.nonzero(as_tuple=True)\n",
    "ratings = X[user_ids, item_ids]\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    predictions = model(user_ids, item_ids)\n",
    "    loss = loss_fn(predictions, ratings)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for 2, 3 is 1.632796049118042\n",
      "Predicted rating for 3, 1 is 3.9782395362854004\n",
      "Predicted rating for 4, 0 is 3.732208728790283\n",
      "Original Matrix: \n",
      " [[2. 2. 4. 5. 1.]\n",
      " [1. 4. 3. 4. 3.]\n",
      " [4. 5. 1. 0. 5.]\n",
      " [5. 0. 2. 3. 3.]\n",
      " [0. 2. 1. 1. 1.]]\n",
      "Reconstructed Matrix: \n",
      " [[2. 2. 4. 5. 1.]\n",
      " [1. 4. 3. 4. 3.]\n",
      " [4. 5. 1. 2. 5.]\n",
      " [5. 4. 2. 3. 3.]\n",
      " [4. 2. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "user_ids, item_ids = (X == 0).nonzero(as_tuple=True)\n",
    "\n",
    "prediction_list = []\n",
    "with torch.inference_mode():\n",
    "    predictions = model(user_ids, item_ids)\n",
    "    predictions = torch.clamp(predictions, min=0, max=5)\n",
    "\n",
    "for user, item, rating in zip(user_ids, item_ids, predictions):\n",
    "    print(f\"Predicted rating for {user}, {item} is {rating}\")\n",
    "\n",
    "reconstructed_matrix = np.zeros_like(X.numpy())\n",
    "\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i in range(n_users):\n",
    "        for j in range(n_items):\n",
    "            user_id = torch.tensor([i])\n",
    "            item_id = torch.tensor([j])\n",
    "            if X[i, j] != 0:\n",
    "                reconstructed_matrix[i, j] = X[i, j].item()\n",
    "            else:\n",
    "                predicted_rating = model(user_id, item_id)\n",
    "                reconstructed_matrix[i, j] = np.round(torch.clamp(predicted_rating, min=0, max=5).detach().numpy().item())\n",
    "\n",
    "print(\"Original Matrix: \\n\", X.numpy())\n",
    "print(\"Reconstructed Matrix: \\n\", reconstructed_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
